\rhead{\textit{Related work}}
\lhead{\thepage}
\chapter{Related work}

This chapter gives a brief understanding of the evolution of semantic segmentation and object detection solved using \ac{ml} based techniques to \ac{dl} based techniques. This section also gives an insight into the approaches used for semantic segmentation and object detection. Taking inspiration from these approaches, we decide upon the architecture that can be used for this work. 


\subsection{Semantic Segmentation}

Section \ref{Semantic Segmentation} describes the process of linking each pixel of an image with a class. This task is one of the grand challenges in the field of computer vision. It all started with researchers using traditional machine learning algorithm \cite{dollar2009integral} with the help of techniques such as edge detection \cite{huang2010image}, clustering \cite{zheng2018image}, region growing \cite{10.1007/978-3-540-76725-1_21} and SIFT \cite{suga2008object}. But all of these techniques required the features to be extracted manually and hence, this becomes a tedious job and requires domain expertise.
\par
Such \ac{ml}-based techniques slowed down around the era of \ac{dl} as it started to take over the world of computer vision because it needs only data. Also, amongst different learning algorithms in the field of \ac{dl}, \ac{cnn} got a tremendous amount of success in the area of semantic segmentation. 
\par
In \ac{dl}, R-CNN \cite{girshick2014rich} used selective search algorithm \cite{uijlings2013selective} to extract region proposals from the image and then applied \ac{cnn} upon each region proposal and achieved record result for PASCAL VOC dataset. This technique was a leading hand in the area of semantic segmentation at that time. Around the same time \cite{DBLP:journals/corr/GuptaGAM14} used \ac{cnn} along with geocentric embedding on RGB-D images for semantic segmentation. After this phase, \ac{fcn} \cite{long2015fully} gained the highest attention as it achieved \ac{sota} result. \ac{fcn} used base model \ac{vgg}16 as the feature extractor and bilinear interpolation technique for the upsampling of feature maps. It also used skip connections for combining low and high layer features in the final feature map to achieve fine-grained segmentation map. \ac{fcn} used only local information which makes semantic segmentation quite ambiguous. Hence, to reduce the ambiguous information from the image, \cite{DBLP:journals/corr/MostajabiYS14} used contextual features and achieved \ac{sota} result. Lately, \cite{DBLP:journals/corr/RonnebergerFB15} used a U shaped network known as U-Net, which consists of a contracting and expansive pathway approach to semantic segmentation. The contracting path is responsible for extracting image features and reduce spatial information; expansive pathway upsamples the contracted feature map. In each upsampling step, the network concatenates the reduced up-convolved feature map with corresponding cropped feature map from contracting pathway. By using both high level and low-level spatial information, U-Net achieves precise segmentation map. Segnet \cite{DBLP:journals/corr/BadrinarayananK15} also follow the same footsteps of U-Net by using an encoder-decoder network. An encoder is used to extract image features, and the decoder uses un-pooling operation to get a segmentation map of a size similar to the input image in order to get a precise localization of the segmented object. 
\par
This work mainly focuses on encoder-decoder architecture. As mentioned above, the encoder is used to extract features, and give a spatially reduced feature map from images, and the decoder does upsampling of the feature maps to achieve segmented map. 
\clearpage

\subsection{Object Detection}

Section \ref{Object Detection} describes the process of detecting instances of visual objects in an image. This task is one of the most major and challenging problems in the area of computer vision. Nearly all of the early object detection algorithms were based on extracting features manually due to the lack of effective image representations. \cite{viola2001rapid} achieved real-time detection of human faces that is faster than other algorithms and with better detection accuracy. This detector follows the most straight-forward way of sliding windows through all possible scales and locations in an image to check if any of the windows contain a human face. Histogram of Oriented Gradients (HOG) by \cite{dalal2005histograms} was the next revelation in this area, which was considered as an important improvement over other detectors. In order to detect multiple objects of different sizes, the HOG detector re-scales the input image numerous times while keeping the size of the sliding window same. HOG detector has proven to be an important foundation for many object detectors. Such traditional methods became saturated slowly and steadily. 
\par
In 2012, the re-birth of \ac{dl} happened, which lead to the application of \ac{cnn} in the field of object detection. RCNN \cite{DBLP:journals/corr/GuptaGAM14} was the first object detector in the \ac{dl} era. The idea behind RCNN was the extraction of a set of object proposals using selective search \cite{van2011segmentation} and each of these proposals is fed into a \ac{cnn} model to extract features. Lastly, linear SVM classifiers are used to predict the presence of an object within each proposal and identify the class of the object. Fast RCNN \cite{girshick2015fast} detector was an improvement over RCNN that enables to simultaneously train a detector and bounding box regressor under similar network configurations. Faster RCNN by \cite{DBLP:journals/corr/RenHG015} was an upgrade of Fast RCNN. It introduced Region Proposal Network (RPN) that enables complimentary region proposals. Components like feature extraction, bounding box regression, proposal detection were integrated into a unified end-to-end learning framework. After a variety of improvements over the above-mentioned networks, \cite{lin2017feature} proposed a top-down architecture with lateral connections in order to build high-level semantics at all scales. This type of architecture shows great advances for detecting objects at various scales. Above mentioned \ac{dl} methods to detect object are categorized as two-stage detectors where one stage extracts object proposals, and the next stage classifies objects contained in the proposals.  
\par
\ac{dl} methods also consist of one-stage object detectors which skip the object proposal step and runs detection directly over an image. YOLO proposed by \cite{DBLP:journals/corr/RedmonDGF15} is a one-stage detector that divides the input image into grids and predicts bounding boxes and probabilities for each of the grid simultaneously. Due to this, YOLO is speedy at detecting objects. However, YOLO suffers from a drop in localization accuracy for small objects. SSD proposed by \cite{liu2016ssd} has paid attention to this problem. SSD uses multi-reference and multi-resolution detection techniques which makes it better at detecting small objects.
\par
This work mainly focuses on one-stage object detection networks. As mentioned above, one-stage detectors skip the region proposal step and run detection directly. 

\clearpage

\subsection{Combining semantic segmentation and object detection}

The above-mentioned steps give a high-level understanding of the architecture to be used for performing both the tasks. This section involves a brief background as to how both the architectures (semantic segmentation and object detection) can be connected using a single common pipeline. 
\par
\cite{salscheider2019simultaneous} uses an encoder-decoder architecture for both the tasks parallelly. An encoder is a feature extractor whose last feature map is shared in between the semantic segmentation head and object detection head. Also, \cite{DBLP:journals/corr/TeichmannWZCU16} also uses an encoder-decoder architecture where the encoder is shared among 3 tasks, namely, object detection, semantic segmentation and image classification. 

\afterpage{\null\newpage}